{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport random\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-06T12:54:18.036360Z","iopub.execute_input":"2021-11-06T12:54:18.036726Z","iopub.status.idle":"2021-11-06T12:54:18.068763Z","shell.execute_reply.started":"2021-11-06T12:54:18.036645Z","shell.execute_reply":"2021-11-06T12:54:18.068057Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import torch\n\nif torch.cuda.is_available():       \n    device = torch.device(\"cuda\")\n\n    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n\n    print('We will use the GPU:', torch.cuda.get_device_name(0))\n\nelse:\n    print('No GPU available, using the CPU instead.')\n    device = torch.device(\"cpu\")","metadata":{"execution":{"iopub.status.busy":"2021-11-05T23:50:18.136128Z","iopub.execute_input":"2021-11-05T23:50:18.136599Z","iopub.status.idle":"2021-11-05T23:50:19.336455Z","shell.execute_reply.started":"2021-11-05T23:50:18.136563Z","shell.execute_reply":"2021-11-05T23:50:19.335595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Getting the Dataset","metadata":{}},{"cell_type":"code","source":"df = pd.read_json('../input/news-category-dataset/News_Category_Dataset_v2.json', lines = True)\nprint(format(df.shape[0]))\ndf.sample(5)","metadata":{"execution":{"iopub.status.busy":"2021-11-06T12:54:25.914139Z","iopub.execute_input":"2021-11-06T12:54:25.914870Z","iopub.status.idle":"2021-11-06T12:54:28.763956Z","shell.execute_reply.started":"2021-11-06T12:54:25.914818Z","shell.execute_reply":"2021-11-06T12:54:28.763259Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"cat_ids = list(df.category.unique()) #use index as id","metadata":{"execution":{"iopub.status.busy":"2021-11-06T12:54:48.768693Z","iopub.execute_input":"2021-11-06T12:54:48.768946Z","iopub.status.idle":"2021-11-06T12:54:48.814042Z","shell.execute_reply.started":"2021-11-06T12:54:48.768918Z","shell.execute_reply":"2021-11-06T12:54:48.813347Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df['label'] = df.apply(lambda row: cat_ids.index(row.category), axis = 1)\n\ndf.sample(10)","metadata":{"execution":{"iopub.status.busy":"2021-11-06T12:54:54.520940Z","iopub.execute_input":"2021-11-06T12:54:54.521590Z","iopub.status.idle":"2021-11-06T12:54:59.140792Z","shell.execute_reply.started":"2021-11-06T12:54:54.521552Z","shell.execute_reply":"2021-11-06T12:54:59.139980Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"headlines = df.headline.values\nlabels = df.label.values","metadata":{"execution":{"iopub.status.busy":"2021-11-06T12:55:02.863595Z","iopub.execute_input":"2021-11-06T12:55:02.863850Z","iopub.status.idle":"2021-11-06T12:55:02.868134Z","shell.execute_reply.started":"2021-11-06T12:55:02.863821Z","shell.execute_reply":"2021-11-06T12:55:02.867187Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"headlines.dtype","metadata":{"execution":{"iopub.status.busy":"2021-11-06T13:00:03.305680Z","iopub.execute_input":"2021-11-06T13:00:03.305949Z","iopub.status.idle":"2021-11-06T13:00:03.312570Z","shell.execute_reply.started":"2021-11-06T13:00:03.305919Z","shell.execute_reply":"2021-11-06T13:00:03.311891Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"from transformers import BertTokenizer\n\n#Use lower case, as in our use case capitalisation style may differ from Huff Post\ntokenizer = BertTokenizer.from_pretrained('/kaggle/input/bert-base-uncased', do_lower_case=True)","metadata":{"execution":{"iopub.status.busy":"2021-11-06T12:56:22.312127Z","iopub.execute_input":"2021-11-06T12:56:22.312702Z","iopub.status.idle":"2021-11-06T12:56:22.656332Z","shell.execute_reply.started":"2021-11-06T12:56:22.312664Z","shell.execute_reply":"2021-11-06T12:56:22.655525Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"input_tokens = [] #tokenized input\nattention_masks = [] #indicates padded tokens\nencoded_dict = tokenizer(list(headlines),\n                         add_special_tokens = True, #For classification markers\n                         padding='longest',\n                         return_attention_mask = True, #To indicate useful data\n                         return_tensors = 'pt') #Pytorch\ninput_tokens = encoded_dict['input_ids']\nattention_masks = encoded_dict['attention_mask']\ninput_tokens, attention_masks","metadata":{"execution":{"iopub.status.busy":"2021-11-06T12:56:24.513299Z","iopub.execute_input":"2021-11-06T12:56:24.513581Z","iopub.status.idle":"2021-11-06T12:58:00.375680Z","shell.execute_reply.started":"2021-11-06T12:56:24.513550Z","shell.execute_reply":"2021-11-06T12:58:00.374868Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"input_tokens.shape, attention_masks.shape, torch.tensor(labels).shape","metadata":{"execution":{"iopub.status.busy":"2021-11-05T23:52:04.249728Z","iopub.execute_input":"2021-11-05T23:52:04.250159Z","iopub.status.idle":"2021-11-05T23:52:04.2577Z","shell.execute_reply.started":"2021-11-05T23:52:04.25012Z","shell.execute_reply":"2021-11-05T23:52:04.256935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import TensorDataset, random_split\n\ndata_length = 200853\ntrain_length = int(0.8*data_length)\n\ndataset = TensorDataset(input_tokens, attention_masks, torch.tensor(labels))\n\ntrain_dataset, valid_dataset = random_split(dataset, [train_length,data_length-train_length])","metadata":{"execution":{"iopub.status.busy":"2021-11-05T23:52:04.260839Z","iopub.execute_input":"2021-11-05T23:52:04.261093Z","iopub.status.idle":"2021-11-05T23:52:04.273867Z","shell.execute_reply.started":"2021-11-05T23:52:04.261061Z","shell.execute_reply":"2021-11-05T23:52:04.273182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n\ntrain_dl = DataLoader(train_dataset,\n                      sampler = RandomSampler(train_dataset),\n                      batch_size = 64)\nvalid_dl = DataLoader(valid_dataset,\n                      sampler = SequentialSampler(valid_dataset),\n                      batch_size = 64)","metadata":{"execution":{"iopub.status.busy":"2021-11-05T23:52:04.274824Z","iopub.execute_input":"2021-11-05T23:52:04.277744Z","iopub.status.idle":"2021-11-05T23:52:04.281969Z","shell.execute_reply.started":"2021-11-05T23:52:04.277717Z","shell.execute_reply":"2021-11-05T23:52:04.281113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training the model","metadata":{}},{"cell_type":"code","source":"from transformers import BertForSequenceClassification\n\nmodel = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n                                                      num_labels = len(cat_ids),\n                                                      output_attentions = False, # Whether the model returns attentions weights.\n                                                      output_hidden_states = False)\n\nmodel.cuda() #Run on GPU","metadata":{"execution":{"iopub.status.busy":"2021-11-05T23:52:04.283153Z","iopub.execute_input":"2021-11-05T23:52:04.283431Z","iopub.status.idle":"2021-11-05T23:52:31.544576Z","shell.execute_reply.started":"2021-11-05T23:52:04.283395Z","shell.execute_reply":"2021-11-05T23:52:31.54384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AdamW\n\noptimizer = AdamW(model.parameters(),\n                  lr = 2e-5,\n                  eps = 1e-8)","metadata":{"execution":{"iopub.status.busy":"2021-11-05T23:52:31.5459Z","iopub.execute_input":"2021-11-05T23:52:31.546528Z","iopub.status.idle":"2021-11-05T23:52:35.527219Z","shell.execute_reply.started":"2021-11-05T23:52:31.546484Z","shell.execute_reply":"2021-11-05T23:52:35.526501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import get_linear_schedule_with_warmup\n#Linearly reduces learning rate from set value to 0 over training\n\nepochs = 2\ntotal_steps = len(train_dl) * epochs\nscheduler = get_linear_schedule_with_warmup(optimizer,\n                                            num_warmup_steps = 0,\n                                            num_training_steps = total_steps)","metadata":{"execution":{"iopub.status.busy":"2021-11-05T23:52:35.528428Z","iopub.execute_input":"2021-11-05T23:52:35.528683Z","iopub.status.idle":"2021-11-05T23:52:35.533945Z","shell.execute_reply.started":"2021-11-05T23:52:35.52865Z","shell.execute_reply":"2021-11-05T23:52:35.532994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def flat_accuracy(preds, labels):\n    pred_flat = np.argmax(preds, axis=1).flatten()\n    labels_flat = labels.flatten()\n    return np.sum(pred_flat == labels_flat) / len(labels_flat)","metadata":{"execution":{"iopub.status.busy":"2021-11-05T23:52:35.535404Z","iopub.execute_input":"2021-11-05T23:52:35.535876Z","iopub.status.idle":"2021-11-05T23:52:35.547074Z","shell.execute_reply.started":"2021-11-05T23:52:35.535839Z","shell.execute_reply":"2021-11-05T23:52:35.546431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for epoch in range(0,epochs):\n    print(\"\\nEpoch num {:}\".format(epoch+1))\n    \n    total_train_loss = 0\n    \n    ##TRAINING\n    \n    model.train() #Training mode\n    \n    for i, batch in enumerate(train_dl):\n        batch_input_tokens = batch[0].to(device)\n        batch_input_mask = batch[1].to(device)\n        batch_labels = batch[2].to(device)\n        \n        model.zero_grad() #Clear grads\n        \n        result = model(batch_input_tokens,\n                       token_type_ids=None, \n                       attention_mask=batch_input_mask, \n                       labels=batch_labels,\n                       return_dict=True)\n\n        loss = result.loss\n        logits = result.logits #Output prior to activation function\n        \n        total_train_loss += loss.item()\n        \n        loss.backward()\n        \n        torch.nn.utils.clip_grad_norm_(model.parameters(),1.) #Prevent exploding gradients\n        \n        optimizer.step() #Changes params\n        \n        scheduler.step() #Changes learning rate (to smaller)\n        \n    avg_train_loss = total_train_loss/len(train_dl)\n    \n    print(\"Training loss: {0:.2f}\".format(avg_train_loss))\n    \n    ##VALIDATION\n    \n    model.eval()\n    \n    total_val_acc = 0\n    total_val_loss = 0\n    \n    for batch in valid_dl:\n        batch_input_tokens = batch[0].to(device)\n        batch_input_mask = batch[1].to(device)\n        batch_labels = batch[2].to(device)\n        \n        with torch.no_grad():\n            result = model(batch_input_tokens,\n                           token_type_ids=None, \n                           attention_mask=batch_input_mask, \n                           labels=batch_labels,\n                           return_dict=True)\n        \n        loss = result.loss\n        logits = result.logits\n        \n        total_val_loss += loss.item()\n        \n        #Back to cpu to calculate accuracy\n        logits = logits.detach().cpu().numpy()\n        b_labels = batch_labels.to('cpu').numpy()\n        total_val_acc += flat_accuracy(logits,b_labels)\n        \n    avg_val_acc = total_val_acc/len(valid_dl)\n    avg_val_loss = total_val_loss/len(valid_dl)\n    print(\"Accuracy: {0:.2f}\".format(avg_val_acc))\n    print(\"Valid loss: {0:.2f}\".format(avg_val_loss))\n","metadata":{"execution":{"iopub.status.busy":"2021-11-06T00:00:18.855978Z","iopub.execute_input":"2021-11-06T00:00:18.856252Z","iopub.status.idle":"2021-11-06T00:11:21.686814Z","shell.execute_reply.started":"2021-11-06T00:00:18.856224Z","shell.execute_reply":"2021-11-06T00:11:21.685254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model.state_dict(), 'headline_classifier.pt')","metadata":{},"execution_count":null,"outputs":[]}]}